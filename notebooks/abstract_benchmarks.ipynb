{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "# Set geomstats background\n",
    "# export GEOMSTATS_BACKEND=numpy\n",
    "import os\n",
    "os.environ['GEOMSTATS_BACKEND'] = 'numpy'\n",
    "\n",
    "import numpy as np\n",
    "import hyperdt.benchmarking as benchmarking\n",
    "from hyperdt.product_space_DT import ProductSpace, ProductSpaceDT\n",
    "from hyperdt.forest import ProductSpaceRF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 1000\n",
    "NUM_CLASSES = 4\n",
    "signatures = [\n",
    "    # [(3, -1.)],\n",
    "    # [(3, 1.)],\n",
    "    # [(3, -1.), (4, -.5)],\n",
    "    # [(3, -1.), (4, 1.)],\n",
    "    # [(3, -1.), (4, 1.), (5, 0.)],\n",
    "    # [(3, -1.), (4, -.5), (3, .5), (4, 1.)],\n",
    "    # [(3, -1.), (4, -.5), (3, .5), (4, 1.), (5, 0.)],\n",
    "    [(5,-1), (5,-1)],\n",
    "    [(5, 1), (5, 1)],\n",
    "    [(5, -1), (5, 1)],\n",
    "    [(2,-1), (2,-1), (2,-1), (2,-1), (2,-1)],\n",
    "    [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1)],\n",
    "    [(2, -1), (2, -1), (2, 0), (2, 1), (2, 1)]\n",
    "    # [(10,-1)],\n",
    "    # [(10, 1)],\n",
    "    # [(10, 0)],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m rnd_seeds, psdt_scores_by_signature, dt_scores_by_signature \u001b[38;5;241m=\u001b[39m benchmarking\u001b[38;5;241m.\u001b[39mcompute_scores_by_signature(\n\u001b[0;32m----> 7\u001b[0m     signatures, \u001b[38;5;241m1000\u001b[39m, NUM_CLASSES, seed\u001b[38;5;241m=\u001b[39mseed, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_seeds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signature, psdt_score, dt_score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(signatures, psdt_scores_by_signature, dt_scores_by_signature):\n\u001b[1;32m      9\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignature\u001b[39m\u001b[38;5;124m\"\u001b[39m: signature,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsdt_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: psdt_score,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: dt_score\n\u001b[1;32m     14\u001b[0m     })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "rnd_seeds, psdt_scores_by_signature, dt_scores_by_signature = benchmarking.compute_scores_by_signature(\n",
    "    signatures, 1000, NUM_CLASSES, seed=seed, max_depth=3, n_seeds=100)\n",
    "for signature, psdt_score, dt_score in zip(signatures, psdt_scores_by_signature, dt_scores_by_signature):\n",
    "    results.append({\n",
    "        \"seed\": seed,\n",
    "        \"signature\": signature,\n",
    "        \"psdt_score\": psdt_score,\n",
    "        \"dt_score\": dt_score\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\H{5, 1} \\times \\H{5, 1}$ & $93.6 \\pm 1.1$ & $97.3 \\pm 0.5^*$\\\\\n",
      "$\\S{5, 1} \\times \\S{5, 1}$ & $62.2 \\pm 1.6$ & $64.1 \\pm 1.5^*$\\\\\n",
      "$\\H{5, 1} \\times \\S{5, 1}$ & $93.7 \\pm 1.1$ & $97.3 \\pm 0.5^*$\\\\\n",
      "$\\H{2, 1} \\times \\H{2, 1} \\times \\H{2, 1} \\times \\H{2, 1} \\times \\H{2, 1}$ & $76.9 \\pm 1.9$ & $78.6 \\pm 1.9^*$\\\\\n",
      "$\\S{2, 1} \\times \\S{2, 1} \\times \\S{2, 1} \\times \\S{2, 1} \\times \\S{2, 1}$ & $60.4 \\pm 1.9$ & $60.6 \\pm 1.9$\\\\\n",
      "$\\H{2, 1} \\times \\H{2, 1} \\times \\E{2} \\times \\S{2, 1} \\times \\S{2, 1}$ & $78.2 \\pm 1.9$ & $79.5 \\pm 1.9^*$\\\\\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# for signature, psdt_scores, dt_scores in zip(signatures, psdt_scores_by_signature, dt_scores_by_signature):\n",
    "for signature, (i, row) in zip(signatures, results.iterrows()):\n",
    "    dt_scores = row[\"dt_score\"]\n",
    "    psdt_scores = row[\"psdt_score\"]\n",
    "    s = []\n",
    "    for component in signature:\n",
    "        if component[1] < 0:\n",
    "            s.append(\"\\H{\" + f\"{component[0]}, {-component[1]}\" + \"}\")\n",
    "        elif component[1] == 0:\n",
    "            s.append(\"\\E{\" + f\"{component[0]}\" + \"}\")\n",
    "        else:\n",
    "            s.append(\"\\S{\" + f\"{component[0]}, {component[1]}\" + \"}\")\n",
    "    print(\"$\" + \" \\\\times \".join(s) + \"$\", end=\" & \")\n",
    "    print(f\"${np.mean(dt_scores) * 100:.1f} \\pm {np.std(dt_scores) / np.sqrt(len(dt_scores)) * 1.96 * 100 :.1f}$\", end=\" & \")\n",
    "    print(f\"${np.mean(psdt_scores) * 100:.1f} \\pm {np.std(psdt_scores) / np.sqrt(len(psdt_scores)) * 1.96 * 100 :.1f}\", end=\"\")\n",
    "\n",
    "    t, p = stats.ttest_rel(dt_scores, psdt_scores)\n",
    "    if p < .05:\n",
    "        print(\"^*$\", end=\"\")\n",
    "    else:\n",
    "        print(\"$\", end=\"\")\n",
    "\n",
    "    print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [10:42<00:00,  5.35s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signature</th>\n",
       "      <th>psdt_score</th>\n",
       "      <th>dt_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(5, -1), (5, -1)]</td>\n",
       "      <td>[0.975, 0.99, 0.865, 0.925, 0.975, 0.97, 0.995...</td>\n",
       "      <td>[0.875, 0.835, 0.84, 0.835, 0.88, 0.845, 0.96,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(5, 1), (5, 1)]</td>\n",
       "      <td>[0.685, 0.485, 0.535, 0.665, 0.525, 0.555, 0.6...</td>\n",
       "      <td>[0.66, 0.475, 0.535, 0.63, 0.455, 0.465, 0.675...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(5, -1), (5, 1)]</td>\n",
       "      <td>[0.975, 0.99, 0.865, 0.95, 0.975, 0.97, 0.995,...</td>\n",
       "      <td>[0.885, 0.88, 0.85, 0.86, 0.87, 0.875, 0.92, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(2, -1), (2, -1), (2, -1), (2, -1), (2, -1)]</td>\n",
       "      <td>[0.73, 0.94, 0.69, 0.8, 0.65, 0.7, 0.83, 0.825...</td>\n",
       "      <td>[0.715, 0.935, 0.705, 0.795, 0.54, 0.665, 0.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]</td>\n",
       "      <td>[0.585, 0.73, 0.445, 0.645, 0.435, 0.545, 0.6,...</td>\n",
       "      <td>[0.65, 0.69, 0.45, 0.715, 0.44, 0.575, 0.61, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[(2, -1), (2, -1), (2, 0), (2, 1), (2, 1)]</td>\n",
       "      <td>[0.785, 0.94, 0.73, 0.8, 0.65, 0.74, 0.82, 0.8...</td>\n",
       "      <td>[0.73, 0.94, 0.635, 0.78, 0.545, 0.71, 0.765, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       signature  \\\n",
       "0                             [(5, -1), (5, -1)]   \n",
       "1                               [(5, 1), (5, 1)]   \n",
       "2                              [(5, -1), (5, 1)]   \n",
       "3  [(2, -1), (2, -1), (2, -1), (2, -1), (2, -1)]   \n",
       "4       [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]   \n",
       "5     [(2, -1), (2, -1), (2, 0), (2, 1), (2, 1)]   \n",
       "\n",
       "                                          psdt_score  \\\n",
       "0  [0.975, 0.99, 0.865, 0.925, 0.975, 0.97, 0.995...   \n",
       "1  [0.685, 0.485, 0.535, 0.665, 0.525, 0.555, 0.6...   \n",
       "2  [0.975, 0.99, 0.865, 0.95, 0.975, 0.97, 0.995,...   \n",
       "3  [0.73, 0.94, 0.69, 0.8, 0.65, 0.7, 0.83, 0.825...   \n",
       "4  [0.585, 0.73, 0.445, 0.645, 0.435, 0.545, 0.6,...   \n",
       "5  [0.785, 0.94, 0.73, 0.8, 0.65, 0.74, 0.82, 0.8...   \n",
       "\n",
       "                                            dt_score  \n",
       "0  [0.875, 0.835, 0.84, 0.835, 0.88, 0.845, 0.96,...  \n",
       "1  [0.66, 0.475, 0.535, 0.63, 0.455, 0.465, 0.675...  \n",
       "2  [0.885, 0.88, 0.85, 0.86, 0.87, 0.875, 0.92, 0...  \n",
       "3  [0.715, 0.935, 0.705, 0.795, 0.54, 0.665, 0.70...  \n",
       "4  [0.65, 0.69, 0.45, 0.715, 0.44, 0.575, 0.61, 0...  \n",
       "5  [0.73, 0.94, 0.635, 0.78, 0.545, 0.71, 0.765, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF version\n",
    "import pandas as pd\n",
    "\n",
    "results_rf = []\n",
    "\n",
    "rnd_seeds, psdt_scores_by_signature, dt_scores_by_signature = benchmarking.compute_scores_by_signature(\n",
    "    signatures, 1000, NUM_CLASSES, seed=0, max_depth=3, n_seeds=20, rf=True\n",
    ")\n",
    "for signature, psdt_score, dt_score in zip(signatures, psdt_scores_by_signature, dt_scores_by_signature):\n",
    "    results_rf.append({\"signature\": signature, \"psdt_score\": psdt_score, \"dt_score\": dt_score})\n",
    "\n",
    "results_rf = pd.DataFrame(results_rf)\n",
    "results_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$90.2 \\pm 3.2$ & $97.0 \\pm 1.4^*$\n",
      "$60.3 \\pm 4.4$ & $61.1 \\pm 4.0$\n",
      "$90.3 \\pm 2.5$ & $97.1 \\pm 1.4^*$\n",
      "$78.0 \\pm 4.7$ & $80.8 \\pm 4.2^*$\n",
      "$58.2 \\pm 4.4$ & $58.3 \\pm 4.7$\n",
      "$78.1 \\pm 4.8$ & $81.6 \\pm 3.9^*$\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# for signature, psdt_scores, dt_scores in zip(signatures, psdt_scores_by_signature, dt_scores_by_signature):\n",
    "for signature, (i, row) in zip(signatures, results_rf.iterrows()):\n",
    "    dt_scores = row[\"dt_score\"]\n",
    "    psdt_scores = row[\"psdt_score\"]\n",
    "    s = []\n",
    "    for component in signature:\n",
    "        if component[1] < 0:\n",
    "            s.append(\"\\H{\" + f\"{component[0]}, {-component[1]}\" + \"}\")\n",
    "        elif component[1] == 0:\n",
    "            s.append(\"\\E{\" + f\"{component[0]}\" + \"}\")\n",
    "        else:\n",
    "            s.append(\"\\S{\" + f\"{component[0]}, {component[1]}\" + \"}\")\n",
    "    # print(\"$\" + \" \\\\times \".join(s) + \"$\", end=\" & \")\n",
    "    print(f\"${np.mean(dt_scores) * 100:.1f} \\pm {np.std(dt_scores) / np.sqrt(len(dt_scores)) * 1.96 * 100 :.1f}$\", end=\" & \")\n",
    "    print(f\"${np.mean(psdt_scores) * 100:.1f} \\pm {np.std(psdt_scores) / np.sqrt(len(psdt_scores)) * 1.96 * 100 :.1f}\", end=\"\")\n",
    "\n",
    "    t, p = stats.ttest_rel(dt_scores, psdt_scores)\n",
    "    if p < .05:\n",
    "        print(\"^*$\", end=\"\")\n",
    "    else:\n",
    "        print(\"$\", end=\"\")\n",
    "\n",
    "    # print(\"\\\\\\\\\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "productDT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
